design.txt

Python is going to be the first output language, so that AQA
style Pseudo code can be converted into first-cut python
for further development. This will be useful for school children
to develop the basis of an algorithm in pseudo code, and then
convert this into Python to further develop it.

JUST DONE

Experimented with zip
Wrote a manual release process

TODO
Write the release process as a release.sh script
Test that it works


--------------------------------------------------------------------------------
MANUAL RELEASE PROCESS (TEMPORARY)

TO RELEASE IT:
(probably want to take the pertinent commands out of pcode_gen.sh and pcode_run.sh)
(probably want a mode of running it that does the lex and yacc parser table build,
but does no actual parse. This will build the parsetab.py for us.


cd build
rm -rf sandbox
./pcode_gen.sh
rm sandbox/ply
cp -r yply/ply sandbox/
./pcode_run.sh
cp ../src/__main__.py sandbox
cd sandbox
zip up the sandbox from within here, into pcode.zip
bring into run directory pcode.zip, src/runtime/arrays.py src/runtime/fileio.py

TO RUN IT:
python pcode.zip < test.pc > test.py

----------------------------------------------------------------------

EXPERIMENTS WITH ZIP

Looks like we'll have to dig into yacc to see how it is opening these two files,
rather than opening as a path, it might need to use a different method to get
access to the embedded resources in the zip.

Davids-MacBook-Air-2:sandbox davidw$ python Archive.zip
WARNING: Couldn't open 'parser.out'. [Errno 20] Not a directory: 'Archive.zip/parser.out'
WARNING: Token 'UNARY' defined, but not used
WARNING: There is 1 unused token
Generating LALR tables
WARNING: Couldn't create 'parsetab'. [Errno 20] Not a directory: 'Archive.zip/parsetab.py'
pcode>

Although it does work, despite these warnings.

The fileio.py and arrays.py have to be in the folder for it to run.
So really we need a way to auto extract those when the __main__.py runs
(presumably there is a way we can read a resource from our zip file
and then just fwrite it out?

Davids-MacBook-Air-2:~ davidw$ python test.py
Traceback (most recent call last):
  File "test.py", line 1, in <module>
    from fileio import *
ImportError: No module named fileio

Would be nice if arrays is only imported if you use an array,
and fileio only imported if you use files.
And an option to embed them in the src.

This is a pre-run packaging issue, so could just squash the imports totally
in the generation process, and have a post-processing that creates a new
file, prepends the imports or the copy of the actual code, then appends
the user code. Closes the file, deletes the original, then renames the new
one as the final code.

This pre-run packager could extract the fileio.py and arrays.py also
if they are needed.

Could add a command line parser to __main__.py so that if you run it
with no arguments, it asks you what the input file and output file name
is (at the moment we just use redirection) - command line arguments
would be better.



--------------------------------------------------------------------------------
PACKAGING AND DISTRIBUTION

The point of this is to be able to package the whole toolsuite up as a python
zip archive with a __main__ in it, and for the runtime support files to magically
pop out of the zip file into the user script directory when you run the tool.
This will make distribution and use much easier.

In theory, just distribute a zip file and give them an instruction on how to
run the tool. All the necessary files will then be bound into a single file,
which works nice as a distributable package.

Could add an option to blurt out the io and array contents into the top of the
out.py file, instead of as separate files, thus generating a single python file
that can be distributed by the end user.

* run an experiment to work out the best way to embed a whole
  python module inside a python module, so that it can be
  programatically streamed out when embedded in a zip file.
  Code it up manually, be careful of escaping quotes etc.

* work out what the interface to this module is - probably
  just call a function with a file handle, and it appends it's
  docstring contents to that file handle (much better than returning
  a string and then writing that, more efficient)

* write a tool that embeds all of the files in a nominated folder
  into a single python file as big docstrings - this will be useful
  for embedding code into a zip package in a way that it can then
  just be streamed out on demand to another file in the filing system.
  Be careful of escaping quotes etc properly.

* Put this tool in the build dir

* Change the build script so that it runs this on the runtime folder
  and generates a runtime.py

* work out path to user script when parser runs

* Test that we can put this inside a zip file, run the zip file
  from python and it generates

* on parser run, auto copy io.py and array.py to user script dir
  (use file read/write rather than copy, so it works from within zip?
  need to verify we can find a way to read resources from a zip, might
  have to embed the code as a docstring so that we can read it out
  as a resource, in case the .zip is execute only.)

* auto import io.py and array.py at top of every program


--------------------------------------------------------------------------------
PACKAGING AND DISTRIBUTION


Look into packaging the whole thing as a zip file with a __main__.py inside it,
and check that this works with both python2 and python3 - i.e. can we just
run python pcode.zip myprog.aqa on any platform and it will work?

The aqa_io.py and aqa_array.py modules will be embedded inside a folder in the zip
and bytestream'ed out into the user script directory every time they run the tool.
That way if they damage the file, it will be replaced on each build.

Need to write some documentation on the grammar with examples

Need to write some documentation on how to run the tool




--------------------------------------------------------------------------------
TIDY UP (LOW PRIORITY STUFF)

comments should pass through unmodified to the output code!!!
(be a real pain do, but anoying for users to loose all their comments
on translation!)

This is really hard to do, because we don't want to make comments a
gramatical item. But to get it positionally correct, the lexer would
have to know about parser state, which is not right


Need to test this works with python2 and python3

Revisit the global variable argument later

Need to add blank lines around fn/proc definitions to space the thing out a bit.
- every def needs a newline before it
- every end of def region needs a newline after it
- need to suppress double newlines, so if already output a blank line
  when starting a new def, don't do it.

This spacing could be a bit subjective.
Really it is probably a PrettyPrinter state machine that needs hooks
into PROC/ENDPROC/FN/ENDFN/STATEMENT, so that we could define different
PrettyPrinter rules or change them independently or share them between
different languages.

Put a comment tag with the date and time stamp of the conversion,
and some traceability to the release date and time stamp of the conversion tool.

Review all the spacing around operators to make sure it is consistent and good.






